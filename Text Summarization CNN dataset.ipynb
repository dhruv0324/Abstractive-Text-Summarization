{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa3d1a2-368f-4a8a-aa03-c01695715f83",
   "metadata": {},
   "source": [
    "# Loading data in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13b06def-fa66-4589-a5db-b129b01f7eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5733342-e257-4be8-a818-badaa018f187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)The Palestinian Authority officially beca...</td>\n",
       "      <td>Membership gives the ICC jurisdiction over all...</td>\n",
       "      <td>f001ec5c4704938247d27a44948eebb37ae98d01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN)Never mind cats having nine lives. A stra...</td>\n",
       "      <td>Theia, a bully breed mix, was apparently hit b...</td>\n",
       "      <td>230c522854991d053fe98a718b1defa077a8efef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(CNN)If you've been following the news lately,...</td>\n",
       "      <td>Mohammad Javad Zarif has spent more time with ...</td>\n",
       "      <td>4495ba8f3a340d97a9df1476f8a35502bcce1f69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN)Five Americans who were monitored for thr...</td>\n",
       "      <td>17 Americans were exposed to the Ebola virus w...</td>\n",
       "      <td>a38e72fed88684ec8d60dd5856282e999dc8c0ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)A Duke student has admitted to hanging a ...</td>\n",
       "      <td>Student is no longer on Duke University campus...</td>\n",
       "      <td>c27cf1b136cc270023de959e7ab24638021bc43f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  (CNN)The Palestinian Authority officially beca...   \n",
       "1  (CNN)Never mind cats having nine lives. A stra...   \n",
       "2  (CNN)If you've been following the news lately,...   \n",
       "3  (CNN)Five Americans who were monitored for thr...   \n",
       "4  (CNN)A Duke student has admitted to hanging a ...   \n",
       "\n",
       "                                          highlights  \\\n",
       "0  Membership gives the ICC jurisdiction over all...   \n",
       "1  Theia, a bully breed mix, was apparently hit b...   \n",
       "2  Mohammad Javad Zarif has spent more time with ...   \n",
       "3  17 Americans were exposed to the Ebola virus w...   \n",
       "4  Student is no longer on Duke University campus...   \n",
       "\n",
       "                                         id  \n",
       "0  f001ec5c4704938247d27a44948eebb37ae98d01  \n",
       "1  230c522854991d053fe98a718b1defa077a8efef  \n",
       "2  4495ba8f3a340d97a9df1476f8a35502bcce1f69  \n",
       "3  a38e72fed88684ec8d60dd5856282e999dc8c0ca  \n",
       "4  c27cf1b136cc270023de959e7ab24638021bc43f  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"CNN-DailyMail.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a191b48e-d83b-4a28-85fc-5cd75f3d2fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)The Palestinian Authority officially beca...</td>\n",
       "      <td>Membership gives the ICC jurisdiction over all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN)Never mind cats having nine lives. A stra...</td>\n",
       "      <td>Theia, a bully breed mix, was apparently hit b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(CNN)If you've been following the news lately,...</td>\n",
       "      <td>Mohammad Javad Zarif has spent more time with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN)Five Americans who were monitored for thr...</td>\n",
       "      <td>17 Americans were exposed to the Ebola virus w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)A Duke student has admitted to hanging a ...</td>\n",
       "      <td>Student is no longer on Duke University campus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  (CNN)The Palestinian Authority officially beca...   \n",
       "1  (CNN)Never mind cats having nine lives. A stra...   \n",
       "2  (CNN)If you've been following the news lately,...   \n",
       "3  (CNN)Five Americans who were monitored for thr...   \n",
       "4  (CNN)A Duke student has admitted to hanging a ...   \n",
       "\n",
       "                                          highlights  \n",
       "0  Membership gives the ICC jurisdiction over all...  \n",
       "1  Theia, a bully breed mix, was apparently hit b...  \n",
       "2  Mohammad Javad Zarif has spent more time with ...  \n",
       "3  17 Americans were exposed to the Ebola virus w...  \n",
       "4  Student is no longer on Duke University campus...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('id', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e324e16-477d-4b10-9503-df15782bd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = df.sample(n=100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dce53bd-5ad6-4482-b1a0-2fe16beed591",
   "metadata": {},
   "source": [
    "# PEGASUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7745f5a9-66c5-4a8e-ad5f-6d8ba43b9057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "pegasus_tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n",
    "pegasus_model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05d9aefd-7c4f-4c38-9657-7ad62e6a5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_pegasus(article, max_length=100):\n",
    "    inputs = pegasus_tokenizer.encode(article, return_tensors=\"pt\", truncation=True)\n",
    "    summary_ids = pegasus_model.generate(inputs, max_length=max_length, num_beams=4, early_stopping=True)\n",
    "    return pegasus_tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65aad36c-83ab-4034-9e5e-8fce64486d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Scores: [0.8368757963180542, 0.8650716543197632, 0.8415181040763855, 0.8718240261077881, 0.8398550748825073, 0.8469235897064209, 0.8339549899101257, 0.859872043132782, 0.8815048933029175, 0.8741775751113892, 0.8328050374984741, 0.8724263906478882, 0.8138409852981567, 0.8291168212890625, 0.8713105320930481, 0.8939358592033386, 0.8477096557617188, 0.8699058890342712, 0.8944743871688843, 0.8369841575622559, 0.8721429109573364, 0.8248619437217712, 0.8221483826637268, 0.8826601505279541, 0.8312482833862305, 0.836970329284668, 0.8731266856193542, 0.8735885620117188, 0.8594568371772766, 0.8159869313240051, 0.854633629322052, 0.8599585294723511, 0.9160825610160828, 0.8665529489517212, 0.8383817076683044, 0.8430576920509338, 0.8546010851860046, 0.8493355512619019, 0.8530657887458801, 0.860209584236145, 0.8462291955947876, 0.8914095163345337, 0.8637242913246155, 0.8204149603843689, 0.9162045121192932, 0.88985276222229, 0.8247300982475281, 0.8776664137840271, 0.7360701560974121, 0.8497639894485474, 0.915302038192749, 0.8722776174545288, 0.8939396142959595, 0.853132963180542, 0.875365674495697, 0.8586177825927734, 0.8660175800323486, 0.878458559513092, 0.8901689648628235, 0.8236504197120667, 0.8719277381896973, 0.8850580453872681, 0.8240165114402771, 0.8237640857696533, 0.8560190200805664, 0.8301960825920105, 0.8950558304786682, 0.8367083668708801, 0.8616016507148743, 0.867932140827179, 0.8002797365188599, 0.832923948764801, 0.858458399772644, 0.856660008430481, 0.8189178109169006, 0.8217276930809021, 0.8326106071472168, 0.8344825506210327, 0.8647100329399109, 0.8514316082000732, 0.8665151596069336, 0.8603695631027222, 0.8686738014221191, 0.8542468547821045, 0.8845216035842896, 0.9008097648620605, 0.9056117534637451, 0.8441102504730225, 0.8645439743995667, 0.8588481545448303, 0.8247321248054504, 0.8450027108192444, 0.9339374303817749, 0.8449866771697998, 0.8478795886039734, 0.8365970253944397, 0.830123782157898, 0.8329730033874512, 0.8262818455696106, 0.8205803632736206]\n",
      "Recall Scores: [0.8539086580276489, 0.8877505660057068, 0.8302853107452393, 0.8768982291221619, 0.8671785593032837, 0.85673987865448, 0.845428466796875, 0.8616442084312439, 0.8804280161857605, 0.8838290572166443, 0.8556930422782898, 0.8867480754852295, 0.8175276517868042, 0.818392276763916, 0.8829997181892395, 0.9190014600753784, 0.8614331483840942, 0.8812777996063232, 0.8766862154006958, 0.8309286832809448, 0.8538733124732971, 0.8380990624427795, 0.8425629138946533, 0.8916248083114624, 0.8077367544174194, 0.8483947515487671, 0.8674560189247131, 0.8551753163337708, 0.8950109481811523, 0.8377076387405396, 0.8696856498718262, 0.8618893027305603, 0.8943233489990234, 0.9129431843757629, 0.857509434223175, 0.8574556708335876, 0.8424316644668579, 0.9032742977142334, 0.866324245929718, 0.8940774202346802, 0.8490137457847595, 0.8792150020599365, 0.8669959306716919, 0.8545149564743042, 0.8347798585891724, 0.8515281677246094, 0.8446656465530396, 0.8776017427444458, 0.7946817874908447, 0.8514270186424255, 0.8575537204742432, 0.85142582654953, 0.904222309589386, 0.8374467492103577, 0.8845984935760498, 0.8503466844558716, 0.8740830421447754, 0.8832314610481262, 0.8590675592422485, 0.8624696731567383, 0.8695225715637207, 0.8673672676086426, 0.8392946124076843, 0.8457509875297546, 0.8612183332443237, 0.8644236922264099, 0.8593529462814331, 0.8461686968803406, 0.8345126509666443, 0.8988802433013916, 0.8290314078330994, 0.8156334161758423, 0.8783485293388367, 0.8436416387557983, 0.8449774980545044, 0.8303727507591248, 0.8191632628440857, 0.8077219128608704, 0.8432848453521729, 0.8645053505897522, 0.8783519864082336, 0.8604380488395691, 0.8904363512992859, 0.8673129081726074, 0.8952129483222961, 0.8559965491294861, 0.8752243518829346, 0.8195790648460388, 0.896277129650116, 0.8713288903236389, 0.8357892632484436, 0.8330656290054321, 0.8937821388244629, 0.8967387080192566, 0.8455420732498169, 0.8595216870307922, 0.8309348225593567, 0.8409020304679871, 0.8092250823974609, 0.819347620010376]\n",
      "F1 Scores: [0.845306396484375, 0.8762644529342651, 0.8358639478683472, 0.8743537068367004, 0.8532981276512146, 0.8518034219741821, 0.8396524786949158, 0.8607572317123413, 0.8809661269187927, 0.8789768218994141, 0.8440939784049988, 0.8795288801193237, 0.8156801462173462, 0.8237196207046509, 0.8771162033081055, 0.9062954187393188, 0.8545162677764893, 0.8755548596382141, 0.8854909539222717, 0.8339454531669617, 0.8629113435745239, 0.831427812576294, 0.8322304487228394, 0.8871198296546936, 0.8193238973617554, 0.8426437973976135, 0.8702821135520935, 0.8642839193344116, 0.8768736720085144, 0.8267045617103577, 0.862093985080719, 0.8609228730201721, 0.9050721526145935, 0.8891433477401733, 0.8478376865386963, 0.8501957058906555, 0.8484727144241333, 0.8754748702049255, 0.8596438765525818, 0.8768166303634644, 0.8476191759109497, 0.8852702975273132, 0.865356981754303, 0.8371178507804871, 0.8735989928245544, 0.8702687621116638, 0.8345788717269897, 0.8776341080665588, 0.7642539143562317, 0.850594699382782, 0.8854873776435852, 0.8617256283760071, 0.8990515470504761, 0.8452171087265015, 0.8799578547477722, 0.8544622659683228, 0.8700316548347473, 0.8808385729789734, 0.8743417263031006, 0.8426132202148438, 0.8707234859466553, 0.8761233687400818, 0.8315854072570801, 0.8346126675605774, 0.8586108088493347, 0.8469642400741577, 0.8768410682678223, 0.8414119482040405, 0.8478408455848694, 0.8831351399421692, 0.8144019246101379, 0.8241879940032959, 0.8682896494865417, 0.8501009941101074, 0.8317435383796692, 0.8260275721549988, 0.825832188129425, 0.8208841681480408, 0.853863000869751, 0.8579186797142029, 0.8723934292793274, 0.860403835773468, 0.8794203996658325, 0.8607302904129028, 0.8898351192474365, 0.8778315782546997, 0.8901587724685669, 0.8316637277603149, 0.8801246285438538, 0.8650435209274292, 0.8302239179611206, 0.8389917016029358, 0.9134186506271362, 0.870093822479248, 0.8467092514038086, 0.8479044437408447, 0.8305290341377258, 0.8369187116622925, 0.8176645636558533, 0.8199635148048401]\n"
     ]
    }
   ],
   "source": [
    "pegasus_precision_scores = []\n",
    "pegasus_recall_scores = []\n",
    "pegasus_f1_scores = []\n",
    "\n",
    "# Iterate over the random samples and generate summaries\n",
    "for index, row in random_samples.iterrows():\n",
    "    article = row['article']\n",
    "    reference_summary = row['highlights']\n",
    "    \n",
    "    # Generate summary using Pegasus with greedy search\n",
    "    generated_summary = generate_summary_pegasus(article)\n",
    "    \n",
    "    # Evaluate the summary using BERTScore\n",
    "    P, R, F1 = score([generated_summary], [reference_summary], lang='en', verbose=False)\n",
    "    \n",
    "    # Store the individual scores\n",
    "    pegasus_precision_scores.append(P.item())\n",
    "    pegasus_recall_scores.append(R.item())\n",
    "    pegasus_f1_scores.append(F1.item())\n",
    "\n",
    "# Print the BERTScore values\n",
    "print(\"Precision Scores:\", pegasus_precision_scores)\n",
    "print(\"Recall Scores:\", pegasus_recall_scores)\n",
    "print(\"F1 Scores:\", pegasus_f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07c317eb-fa1e-49e0-ac09-4fd84e9eb4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Precision    Recall  F1 Score\n",
      "0    0.836876  0.853909  0.845306\n",
      "1    0.865072  0.887751  0.876264\n",
      "2    0.841518  0.830285  0.835864\n",
      "3    0.871824  0.876898  0.874354\n",
      "4    0.839855  0.867179  0.853298\n",
      "..        ...       ...       ...\n",
      "95   0.836597  0.859522  0.847904\n",
      "96   0.830124  0.830935  0.830529\n",
      "97   0.832973  0.840902  0.836919\n",
      "98   0.826282  0.809225  0.817665\n",
      "99   0.820580  0.819348  0.819964\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "pegasus_results_df = pd.DataFrame({\n",
    "    'Precision': pegasus_precision_scores,\n",
    "    'Recall': pegasus_recall_scores,\n",
    "    'F1 Score': pegasus_f1_scores\n",
    "})\n",
    "\n",
    "print(pegasus_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93edb737-7e25-42e3-bdf1-62927e8bfb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pegasus_results_df.to_excel('pegasus_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4b13c3-9a50-4207-ba68-0ca85f09a899",
   "metadata": {},
   "source": [
    "# BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "737204d8-645c-438f-89a4-bf8d2464145f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruva Sandu\\pythonlab\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dhruva Sandu\\.cache\\huggingface\\hub\\models--facebook--bart-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "bart_tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "133872a4-659b-4829-946a-65944c93e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_bart(article, max_length=100):\n",
    "    inputs = bart_tokenizer.encode(article, return_tensors=\"pt\", truncation=True)\n",
    "    summary_ids = bart_model.generate(inputs, max_length=max_length, num_beams=4, early_stopping=True)\n",
    "    return bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3bba668e-bd54-406d-a1e7-55e322394c15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Scores: [0.815876841545105, 0.8645640015602112, 0.8504435420036316, 0.8732391595840454, 0.8515278697013855, 0.805774450302124, 0.8262912034988403, 0.8710603713989258, 0.8939869403839111, 0.8597856760025024, 0.8560997247695923, 0.8866323828697205, 0.8619765639305115, 0.8276309967041016, 0.8726577162742615, 0.8589812517166138, 0.8709471821784973, 0.8418046236038208, 0.8822752237319946, 0.8729409575462341, 0.8877543210983276, 0.8220746517181396, 0.85614013671875, 0.882369875907898, 0.8702179789543152, 0.8683891296386719, 0.8753172159194946, 0.8503544926643372, 0.8818186521530151, 0.8133077621459961, 0.8616291284561157, 0.8655785322189331, 0.8349761366844177, 0.8464046716690063, 0.851706862449646, 0.8813564777374268, 0.8595131635665894, 0.8559266328811646, 0.8382440805435181, 0.8671979308128357, 0.8347077369689941, 0.8841463923454285, 0.8680112361907959, 0.8127490282058716, 0.9069778323173523, 0.8268044590950012, 0.8532711863517761, 0.8749016523361206, 0.8263274431228638, 0.861912727355957, 0.8649362325668335, 0.8424636125564575, 0.8767905235290527, 0.8800050020217896, 0.860535740852356, 0.8716340065002441, 0.849168062210083, 0.8776188492774963, 0.879506528377533, 0.8330563902854919, 0.877980649471283, 0.8657013177871704, 0.8458606004714966, 0.858688235282898, 0.9072208404541016, 0.842361330986023, 0.8518013954162598, 0.8586256504058838, 0.8689522743225098, 0.8880385756492615, 0.8605553507804871, 0.905017077922821, 0.8642171621322632, 0.8603793382644653, 0.8290219306945801, 0.8210306167602539, 0.8112933039665222, 0.868192195892334, 0.8848415017127991, 0.843778669834137, 0.8627742528915405, 0.840267539024353, 0.877155601978302, 0.8494058847427368, 0.8634004592895508, 0.8668948411941528, 0.8786709308624268, 0.8873908519744873, 0.8554279804229736, 0.8706058263778687, 0.872868537902832, 0.8556956648826599, 0.8886349201202393, 0.8353270292282104, 0.8621236085891724, 0.8492533564567566, 0.8744794726371765, 0.8489292860031128, 0.8361207246780396, 0.8236329555511475]\n",
      "Recall Scores: [0.8435143232345581, 0.8890953660011292, 0.8737638592720032, 0.8872483968734741, 0.8843639492988586, 0.8185232877731323, 0.8466013669967651, 0.8853356242179871, 0.9094924330711365, 0.8665700554847717, 0.8926183581352234, 0.8944519758224487, 0.8581588864326477, 0.8238382935523987, 0.893154501914978, 0.8724172115325928, 0.9012921452522278, 0.8268332481384277, 0.869375467300415, 0.9012970328330994, 0.8802661895751953, 0.8469081521034241, 0.8906524181365967, 0.9027466773986816, 0.8762187957763672, 0.8752676844596863, 0.8685353398323059, 0.8568940758705139, 0.924566924571991, 0.8397036194801331, 0.891057014465332, 0.9092698693275452, 0.8919780254364014, 0.8683659434318542, 0.8920119404792786, 0.9153751730918884, 0.8311994671821594, 0.9080228805541992, 0.8604820966720581, 0.8962898850440979, 0.8339978456497192, 0.8935678601264954, 0.8705703020095825, 0.8678955435752869, 0.8887588977813721, 0.848434329032898, 0.8656237125396729, 0.8835433721542358, 0.8478558659553528, 0.8802019357681274, 0.8885469436645508, 0.8361890316009521, 0.8853360414505005, 0.8541398644447327, 0.8883476853370667, 0.8871710896492004, 0.8657155632972717, 0.8876492977142334, 0.8819901943206787, 0.844741702079773, 0.8894412517547607, 0.8584238886833191, 0.8594849109649658, 0.9073855876922607, 0.9176927804946899, 0.874747097492218, 0.8576807379722595, 0.8677686452865601, 0.8564309477806091, 0.9234457015991211, 0.8555688858032227, 0.9287548065185547, 0.8701106309890747, 0.8550691604614258, 0.8442901372909546, 0.8475440740585327, 0.8018024563789368, 0.8207873702049255, 0.8732030391693115, 0.8670650720596313, 0.8646827340126038, 0.8530392050743103, 0.8973228335380554, 0.8732315301895142, 0.8760821223258972, 0.8695759773254395, 0.871166467666626, 0.8654034733772278, 0.9042322635650635, 0.9008654952049255, 0.9007145166397095, 0.8663691282272339, 0.9038618206977844, 0.877685010433197, 0.8520087003707886, 0.8854499459266663, 0.8807753920555115, 0.8807864189147949, 0.8493692278862, 0.8667140603065491]\n",
      "F1 Scores: [0.8294654488563538, 0.8766581416130066, 0.8619459867477417, 0.8801880478858948, 0.8676353693008423, 0.8120988011360168, 0.8363229632377625, 0.8781399130821228, 0.9016730189323425, 0.863164484500885, 0.873977780342102, 0.8905250430107117, 0.8600634932518005, 0.8257303237915039, 0.8827871680259705, 0.8656470775604248, 0.8858598470687866, 0.8342517614364624, 0.8757778406143188, 0.8868924379348755, 0.8839944005012512, 0.8343066573143005, 0.8730553388595581, 0.892441987991333, 0.8732080459594727, 0.8718147873878479, 0.8719130754470825, 0.8536117672920227, 0.9026869535446167, 0.8262949585914612, 0.8760960102081299, 0.8868863582611084, 0.8625363111495972, 0.8572447299957275, 0.8713935017585754, 0.898043692111969, 0.8451191782951355, 0.8812054395675659, 0.8492175340652466, 0.8815039396286011, 0.8343526721000671, 0.888832151889801, 0.8692889213562012, 0.839417576789856, 0.8977759480476379, 0.8374797105789185, 0.8594030141830444, 0.8792012333869934, 0.8369532227516174, 0.8709613680839539, 0.8765826225280762, 0.8393145799636841, 0.8810425400733948, 0.8668795228004456, 0.8742205500602722, 0.8793339729309082, 0.8573619723320007, 0.8826056122779846, 0.8807465434074402, 0.8388583660125732, 0.8836737871170044, 0.8620472550392151, 0.8526183366775513, 0.8823655247688293, 0.9124267101287842, 0.858248770236969, 0.8547309041023254, 0.8631728887557983, 0.8626461029052734, 0.9053961038589478, 0.8580548763275146, 0.9167323112487793, 0.8671539425849915, 0.8577160835266113, 0.8365863561630249, 0.8340766429901123, 0.8065199255943298, 0.8438245058059692, 0.8789837956428528, 0.855263352394104, 0.8637273907661438, 0.8466052412986755, 0.8871245980262756, 0.8611539602279663, 0.8696950078010559, 0.868233323097229, 0.874902606010437, 0.8762592673301697, 0.879153311252594, 0.8854773044586182, 0.8865728974342346, 0.860999345779419, 0.8961837291717529, 0.8559823632240295, 0.8570363521575928, 0.8669740557670593, 0.8776161074638367, 0.8645644783973694, 0.8426929116249084, 0.8446245193481445]\n"
     ]
    }
   ],
   "source": [
    "bart_precision_scores = []\n",
    "bart_recall_scores = []\n",
    "bart_f1_scores = []\n",
    "\n",
    "for index, row in random_samples.iterrows():\n",
    "    article = row['article']\n",
    "    reference_summary = row['highlights']\n",
    "    \n",
    "    # Generate summary using T5 with greedy search\n",
    "    generated_summary = generate_summary_bart(article)\n",
    "    \n",
    "    # Evaluate the summary using BERTScore\n",
    "    P, R, F1 = score([generated_summary], [reference_summary], lang='en', verbose=False)\n",
    "    \n",
    "    # Store the individual scores\n",
    "    bart_precision_scores.append(P.item())\n",
    "    bart_recall_scores.append(R.item())\n",
    "    bart_f1_scores.append(F1.item())\n",
    "\n",
    "# Print the BERTScore values\n",
    "print(\"Precision Scores:\", bart_precision_scores)\n",
    "print(\"Recall Scores:\", bart_recall_scores)\n",
    "print(\"F1 Scores:\", bart_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "503d3d75-bcd0-4da8-9c8e-ca7b3b41470e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Precision    Recall  F1 Score\n",
      "0    0.815877  0.843514  0.829465\n",
      "1    0.864564  0.889095  0.876658\n",
      "2    0.850444  0.873764  0.861946\n",
      "3    0.873239  0.887248  0.880188\n",
      "4    0.851528  0.884364  0.867635\n",
      "..        ...       ...       ...\n",
      "95   0.849253  0.885450  0.866974\n",
      "96   0.874479  0.880775  0.877616\n",
      "97   0.848929  0.880786  0.864564\n",
      "98   0.836121  0.849369  0.842693\n",
      "99   0.823633  0.866714  0.844625\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "bart_results_df = pd.DataFrame({\n",
    "    'Precision': bart_precision_scores,\n",
    "    'Recall': bart_recall_scores,\n",
    "    'F1 Score': bart_f1_scores\n",
    "})\n",
    "\n",
    "print(bart_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6c43c8c-314e-400d-8d68-bf54771ce1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_results_df.to_excel('bart_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e05bfe-a920-4b0f-bc44-96efbe44527c",
   "metadata": {},
   "source": [
    "# T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6590e0f-dd5a-4d30-bffa-65434c5616ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-large\")\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67a994bb-03a2-4943-94ae-c3670e94bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_t5(article, max_length=100):\n",
    "    inputs = t5_tokenizer.encode(\"summarize: \" + article, return_tensors=\"pt\", truncation=True)\n",
    "    summary_ids = t5_model.generate(inputs, max_length=max_length, num_beams=4, early_stopping=True)\n",
    "    return t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9421a12-50d8-4ade-aaf9-e830dc1cac30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Scores: [0.8548189997673035, 0.889518678188324, 0.8833594918251038, 0.8683274388313293, 0.8528497815132141, 0.8903371691703796, 0.8978610038757324, 0.88690185546875, 0.9376890063285828, 0.864109218120575, 0.8806644678115845, 0.8609111309051514, 0.8889483213424683, 0.8448965549468994, 0.9071764945983887, 0.9371885061264038, 0.8799736499786377, 0.8883851766586304, 0.8989431262016296, 0.909895122051239, 0.9283798933029175, 0.8629339933395386, 0.846335768699646, 0.8975170254707336, 0.8528536558151245, 0.8580727577209473, 0.8684893846511841, 0.85289466381073, 0.9054502248764038, 0.8300272226333618, 0.866995096206665, 0.8675549030303955, 0.87000572681427, 0.8636898398399353, 0.8691647052764893, 0.9374569058418274, 0.8456259369850159, 0.8955625295639038, 0.8634824752807617, 0.8650701642036438, 0.8635446429252625, 0.8620753288269043, 0.8805084824562073, 0.8264967799186707, 0.9453151226043701, 0.8924005031585693, 0.8808873891830444, 0.8816272020339966, 0.8569580316543579, 0.8446770906448364, 0.8786418437957764, 0.8927757740020752, 0.8883750438690186, 0.8691139817237854, 0.8802403807640076, 0.8468946218490601, 0.8628752827644348, 0.9010987877845764, 0.8841208219528198, 0.8442469239234924, 0.8693363070487976, 0.8758058547973633, 0.8215489387512207, 0.9046379923820496, 0.8654944896697998, 0.8661936521530151, 0.8483774065971375, 0.8670142292976379, 0.8657119870185852, 0.8526024222373962, 0.8658236265182495, 0.9006773233413696, 0.8664954304695129, 0.8666495084762573, 0.8648935556411743, 0.8429219126701355, 0.8000600337982178, 0.839675784111023, 0.8819136619567871, 0.877886950969696, 0.8883593678474426, 0.8403056263923645, 0.8774837851524353, 0.8747344613075256, 0.867917001247406, 0.8861874938011169, 0.894913911819458, 0.8905879259109497, 0.8336175084114075, 0.8948726058006287, 0.8612170219421387, 0.8659060597419739, 0.8770934343338013, 0.8606116771697998, 0.8754992485046387, 0.848395586013794, 0.8634284734725952, 0.870263934135437, 0.8548495173454285, 0.9079316854476929]\n",
      "Recall Scores: [0.852082371711731, 0.883310854434967, 0.9058291912078857, 0.8523342609405518, 0.862548291683197, 0.8415637016296387, 0.8703378438949585, 0.8831860423088074, 0.9277914762496948, 0.8789804577827454, 0.8720789551734924, 0.8499147891998291, 0.8543639183044434, 0.8320609331130981, 0.898772656917572, 0.8742645978927612, 0.8625414967536926, 0.8571822643280029, 0.8975703716278076, 0.8896169662475586, 0.8882004022598267, 0.8695405721664429, 0.8716113567352295, 0.8890447616577148, 0.8516388535499573, 0.8585954308509827, 0.8647756576538086, 0.8402565717697144, 0.8809812664985657, 0.840387225151062, 0.8494640588760376, 0.8669527173042297, 0.8565974235534668, 0.8303524851799011, 0.8726506233215332, 0.9577686786651611, 0.8040229678153992, 0.8623420000076294, 0.8722113370895386, 0.8747472763061523, 0.8417006731033325, 0.8705634474754333, 0.844397246837616, 0.8555711507797241, 0.8978284597396851, 0.8791093826293945, 0.8644363880157471, 0.8573062419891357, 0.8579239845275879, 0.8639768958091736, 0.8506764769554138, 0.8528878092765808, 0.8750706911087036, 0.8380297422409058, 0.8748987317085266, 0.8452019095420837, 0.8504737019538879, 0.8728620409965515, 0.8652384877204895, 0.8631505370140076, 0.8527435064315796, 0.8611173629760742, 0.8451638221740723, 0.8994308710098267, 0.8525744080543518, 0.8753234148025513, 0.8311749696731567, 0.870123028755188, 0.8554984331130981, 0.8839142322540283, 0.8507948517799377, 0.9001938700675964, 0.8553757667541504, 0.860061764717102, 0.8537919521331787, 0.854230523109436, 0.7724164724349976, 0.7994379997253418, 0.839277982711792, 0.8616422414779663, 0.8620412945747375, 0.8537082672119141, 0.8873211145401001, 0.864884078502655, 0.8468137979507446, 0.8570932745933533, 0.8778116703033447, 0.8576159477233887, 0.8600431680679321, 0.8972377777099609, 0.8475152850151062, 0.8756216168403625, 0.8645948171615601, 0.8685276508331299, 0.8577218651771545, 0.8553182482719421, 0.8569607138633728, 0.8552240133285522, 0.8433742523193359, 0.8840522766113281]\n",
      "F1 Scores: [0.8534485101699829, 0.8864038586616516, 0.8944532871246338, 0.860256552696228, 0.8576716184616089, 0.8652636408805847, 0.8838852047920227, 0.8850399851799011, 0.9327139854431152, 0.8714814186096191, 0.8763506412506104, 0.8553776144981384, 0.8713130354881287, 0.8384296298027039, 0.9029549956321716, 0.904633641242981, 0.8711704015731812, 0.8725048303604126, 0.898256242275238, 0.899641752243042, 0.9078457951545715, 0.8662247061729431, 0.8587875962257385, 0.8932608366012573, 0.8522458076477051, 0.8583340644836426, 0.8666285872459412, 0.8465284705162048, 0.893048107624054, 0.835175096988678, 0.8581400513648987, 0.8672537207603455, 0.8632495403289795, 0.8466931581497192, 0.8709042072296143, 0.9475039839744568, 0.8242998719215393, 0.8786383271217346, 0.8678249716758728, 0.869881808757782, 0.852482795715332, 0.8662985563278198, 0.8620748519897461, 0.8407827019691467, 0.9209600687026978, 0.8857050538063049, 0.872584342956543, 0.869296669960022, 0.8574407696723938, 0.854218065738678, 0.8644329905509949, 0.8723760843276978, 0.8816726803779602, 0.8532888293266296, 0.8775614500045776, 0.8460474610328674, 0.8566296100616455, 0.886755645275116, 0.8745777010917664, 0.8535941243171692, 0.8609600067138672, 0.8683995008468628, 0.833189070224762, 0.902026891708374, 0.8589859008789062, 0.8707345724105835, 0.8396881222724915, 0.8685658574104309, 0.8605749011039734, 0.8679760098457336, 0.858243465423584, 0.9004355669021606, 0.8608996868133545, 0.8633430600166321, 0.8593068718910217, 0.8485385775566101, 0.7859952449798584, 0.8190629482269287, 0.8600677847862244, 0.8696888089179993, 0.8750024437904358, 0.8469539880752563, 0.8823750615119934, 0.8697814345359802, 0.8572355508804321, 0.8713976144790649, 0.8862802982330322, 0.873790979385376, 0.8466241359710693, 0.8960535526275635, 0.8543111681938171, 0.8707367181777954, 0.8707993030548096, 0.8645515441894531, 0.8665193915367126, 0.8518428206443787, 0.8601824045181274, 0.8626784086227417, 0.849073052406311, 0.895832896232605]\n"
     ]
    }
   ],
   "source": [
    "t5_precision_scores = []\n",
    "t5_recall_scores = []\n",
    "t5_f1_scores = []\n",
    "\n",
    "for index, row in random_samples.iterrows():\n",
    "    article = row['article']\n",
    "    reference_summary = row['highlights']\n",
    "    \n",
    "    # Generate summary using T5 with greedy search\n",
    "    generated_summary = generate_summary_t5(article)\n",
    "    \n",
    "    # Evaluate the summary using BERTScore\n",
    "    P, R, F1 = score([generated_summary], [reference_summary], lang='en', verbose=False)\n",
    "    \n",
    "    # Store the individual scores\n",
    "    t5_precision_scores.append(P.item())\n",
    "    t5_recall_scores.append(R.item())\n",
    "    t5_f1_scores.append(F1.item())\n",
    "\n",
    "# Print the BERTScore values\n",
    "print(\"Precision Scores:\", t5_precision_scores)\n",
    "print(\"Recall Scores:\", t5_recall_scores)\n",
    "print(\"F1 Scores:\", t5_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fedb92bf-81c4-4865-bca4-0d68995aca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Precision    Recall  F1 Score\n",
      "0    0.854819  0.852082  0.853449\n",
      "1    0.889519  0.883311  0.886404\n",
      "2    0.883359  0.905829  0.894453\n",
      "3    0.868327  0.852334  0.860257\n",
      "4    0.852850  0.862548  0.857672\n",
      "..        ...       ...       ...\n",
      "95   0.848396  0.855318  0.851843\n",
      "96   0.863428  0.856961  0.860182\n",
      "97   0.870264  0.855224  0.862678\n",
      "98   0.854850  0.843374  0.849073\n",
      "99   0.907932  0.884052  0.895833\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "t5_results_df = pd.DataFrame({\n",
    "    'Precision': t5_precision_scores,\n",
    "    'Recall': t5_recall_scores,\n",
    "    'F1 Score': t5_f1_scores\n",
    "})\n",
    "\n",
    "print(t5_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a04d104-2e29-43e6-8b65-eb8e04b9380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_results_df.to_excel('t5_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185cb06-5a60-4efb-b5d6-f88696b2b5c2",
   "metadata": {},
   "source": [
    "# Sample Text and Reference Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fdee34fa-6e7f-4232-ab09-c0cc26b086fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:\n",
      "(CNN)Blinky and Pinky on the Champs Elysees? Inky and Clyde running down Broadway? Power pellets on the Embarcadero? Leave it to Google to make April Fools' Day into throwback fun by combining Google Maps with Pac-Man. The massive tech company is known for its impish April Fools' Day pranks, and Google Maps has been at the center of a few, including a Pokemon Challenge and a treasure map. This year the company was a day early to the party, rolling out the Pac-Man game Tuesday. It's easy to play: Simply pull up Google Maps on your desktop browser, click on the Pac-Man icon on the lower left, and your map suddenly becomes a Pac-Man course. Twitterers have been tickled by the possibilities, playing Pac-Man in Manhattan, on the University of Illinois quad, in central London and down crooked Lombard Street in San Francisco, among many locations: .\n",
      "\n",
      "\n",
      "Highlight:\n",
      "Google Maps has a temporary Pac-Man function . Google has long been fond of April Fools' Day pranks and games . Many people are turning their cities into Pac-Man courses .\n"
     ]
    }
   ],
   "source": [
    "article_index = 976\n",
    "text = df.loc[article_index, 'article']\n",
    "highlight = df.loc[article_index, 'highlights']\n",
    "print(\"Article:\")\n",
    "print(text)\n",
    "print(\"\\n\\nHighlight:\")\n",
    "print(highlight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d321dfd-5fbc-4e45-bdcf-963fb46bef90",
   "metadata": {},
   "source": [
    "# Model Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb70c3-102c-4112-ba9d-e1792dc8ba86",
   "metadata": {},
   "source": [
    "## PEGASUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3149bd9b-c951-4b06-92ef-4f1cfdfef1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave it to Google to make April Fools' Day into throwback fun by combining Google Maps with Pac-Man.\n"
     ]
    }
   ],
   "source": [
    "pegasus_summary = generate_summary_pegasus(text)\n",
    "print(pegasus_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdab9830-1dbf-433d-8957-ac72cdb36e3f",
   "metadata": {},
   "source": [
    "## BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d61a35fe-6129-417a-b248-e5c9c2f5f906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CNN)Blinky and Pinky on the Champs Elysees? Inky and Clyde running down Broadway? Power pellets on the Embarcadero? Leave it to Google to make April Fools' Day into throwback fun by combining Google Maps with Pac-Man. The massive tech company is known for its impish April Fool's Day pranks, and Google Maps has been at the center of a few, including a Pokemon Challenge and a treasure map. This year\n"
     ]
    }
   ],
   "source": [
    "bart_summary = generate_summary_bart(text)\n",
    "print(bart_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e475d5-8341-416c-ab83-374adc9fd083",
   "metadata": {},
   "source": [
    "## T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25d0a9f6-4f78-4f90-954f-0ad1bdf215d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google is known for its impish April Fools' day pranks. this year the company was a day early to the party, rolling out the Pac-man game.\n"
     ]
    }
   ],
   "source": [
    "t5_summary = generate_summary_t5(text)\n",
    "print(t5_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037cf0e9-b288-4f67-bd12-ae91f3fedf23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
